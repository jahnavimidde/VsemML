{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahnavimidde/VsemML/blob/main/unit5_neuralnetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lVogT_j6i36K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Perceptron** is the simplest type of artificial neural network"
      ],
      "metadata": {
        "id": "GZR2clyJkJw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "print(y)\n",
        "#taking only two classes for applying simple perceptron\n",
        "X_binary = X[y != 2]\n",
        "y_binary = y[y != 2]\n",
        "print(y_binary)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_binary = scaler.fit_transform(X_binary)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFDkwJxLj-Yv",
        "outputId": "ed4f80e2-7974-4637-99f0-885248e42a04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#simple perceptron\n",
        "weights = np.random.randn(X_train.shape[1])\n",
        "bias = np.random.randn()\n",
        "lr = 0.1\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for xi, target in zip(X_train, y_train):\n",
        "        linear_output = np.dot(xi, weights) + bias\n",
        "        y_pred = 1 if linear_output >= 0 else 0\n",
        "        error = target - y_pred\n",
        "        weights += lr * error * xi\n",
        "        bias += lr * error\n",
        "\n",
        "#checking accuracy of perceptron\n",
        "preds = [1 if np.dot(x, weights) + bias >= 0 else 0 for x in X_test]\n",
        "print(\"Accuracy (Simple Perceptron):\", accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myobT5bykbQQ",
        "outputId": "1fa0c97b-6442-461b-fd9a-02e8f8dd315b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Simple Perceptron): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **sigmoid function** is a mathematical function that maps any input value to an output between **0 and 1**\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "T5Ag_M5NkvpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "\n",
        "y = np.array([0, 0, 0, 1])"
      ],
      "metadata": {
        "id": "nCqnts5-nn3J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def train_perceptron(X, y, lr=0.1, epochs=10000):\n",
        "    weights = np.random.randn(X.shape[1])\n",
        "    bias = np.random.randn()\n",
        "    for _ in range(epochs):\n",
        "        for xi, target in zip(X, y):\n",
        "            z = np.dot(xi, weights) + bias\n",
        "            y_pred = sigmoid(z)\n",
        "            error = target - y_pred\n",
        "            weights += lr * error * xi\n",
        "            bias += lr * error\n",
        "    return weights, bias\n",
        "\n",
        "#AND Gate\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y_and = np.array([0,0,0,1])\n",
        "w_and, b_and = train_perceptron(X, y_and)\n",
        "\n",
        "print(\"\\nAND Gate Predictions:\")\n",
        "for x in X:\n",
        "    print(f\"{x} -> {sigmoid(np.dot(x, w_and)+b_and) >= 0.5}\")\n",
        "\n",
        "#OR Gate\n",
        "y_or = np.array([0,1,1,1])\n",
        "w_or, b_or = train_perceptron(X, y_or)\n",
        "\n",
        "print(\"\\nOR Gate Predictions:\")\n",
        "for x in X:\n",
        "    print(f\"{x} -> {sigmoid(np.dot(x, w_or)+b_or) >= 0.5}\")\n",
        "\n",
        "#XOR Gate (non-linear, perceptron alone fails)\n",
        "y_xor = np.array([0,1,1,0])\n",
        "w_xor, b_xor = train_perceptron(X, y_xor)\n",
        "\n",
        "print(\"\\nXOR Gate Predictions (Perceptron fails for XOR):\")\n",
        "for x in X:\n",
        "    print(f\"{x} -> {sigmoid(np.dot(x, w_xor)+b_xor) >= 0.5}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqSSzIkfn4Oh",
        "outputId": "b554af72-9541-4a72-e3f4-e0ccb0c4291b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AND Gate Predictions:\n",
            "[0 0] -> False\n",
            "[0 1] -> False\n",
            "[1 0] -> False\n",
            "[1 1] -> True\n",
            "\n",
            "OR Gate Predictions:\n",
            "[0 0] -> False\n",
            "[0 1] -> True\n",
            "[1 0] -> True\n",
            "[1 1] -> True\n",
            "\n",
            "XOR Gate Predictions (Perceptron fails for XOR):\n",
            "[0 0] -> True\n",
            "[0 1] -> True\n",
            "[1 0] -> False\n",
            "[1 1] -> False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**why is it failing for xor?**\n",
        "That’s why a linear model (like a perceptron) fails — it can only create a straight-line decision boundary."
      ],
      "metadata": {
        "id": "_-LyQ_p4oWU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each epoch:\n",
        "\n",
        "You predict output using sigmoid.\n",
        "\n",
        "Compute error between true label (target) and predicted (y_pred).\n",
        "\n",
        "Adjust weights (w) and bias (b) in direction of error.\n",
        "\n",
        "**So the perceptron learns by reducing prediction error gradually.**"
      ],
      "metadata": {
        "id": "dCQ56JPyl-Xm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An MLP (Multilayer Perceptron) is a type of feedforward neural network consisting of:\n",
        "\n",
        "Input layer – takes your features (X)\n",
        "\n",
        "Hidden layer(s) – where non-linear transformations happen\n",
        "\n",
        "Output layer – gives predictions (like 0 or 1)\n",
        "\n",
        "Unlike a simple perceptron, MLP can learn non-linear decision boundaries"
      ],
      "metadata": {
        "id": "NmTknMVQmfTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([0,1,1,0])  # XOR logic\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(2,), activation='logistic', max_iter=10000)\n",
        "mlp.fit(X, y)\n",
        "\n",
        "print(\"\\nMLP (Single Hidden Layer) for XOR:\")\n",
        "for x in X:\n",
        "    print(f\"{x} -> {mlp.predict([x])[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x987uWVnl_nI",
        "outputId": "5b838387-1cac-45b7-b3d8-0b38d3e4b8f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP (Single Hidden Layer) for XOR:\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "parameters of mlp\n",
        "\n",
        "---\n",
        "hidden layer-- (internal computations) , used for handling complex data goes through decisions\n",
        "\n",
        "activation -- introduces non-linearity and helps faster training.\n",
        "\n",
        "max_iter-- no.of iterations"
      ],
      "metadata": {
        "id": "oNE_aMm-mwoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP ON minst dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X_mnist, y_mnist = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "#Subset for faster training\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_mnist[:10000], y_mnist[:10000], test_size=0.2, random_state=42)\n",
        "\n",
        "mlp_mnist = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=20)\n",
        "mlp_mnist.fit(X_train, y_train)\n",
        "y_pred = mlp_mnist.predict(X_test)\n",
        "print(\"MNIST Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCHeRXbcmRmD",
        "outputId": "95d9e995-7899-4023-c244-7680d8c643e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST Accuracy: 0.947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RvhmvZQ8myY2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}