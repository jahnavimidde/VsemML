{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_YfQWWak8O8a",
        "0m3ihRxxonfq"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahnavimidde/VsemML/blob/main/Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLvDPfFe7QRK",
        "outputId": "8b1de6f3-44a3-49e6-fd15-ec5e90cadfa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "#Data Collection\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/titanic_train (1).csv\")\n",
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling null values\n",
        "df.ffill(inplace=True) #Forward fill\n",
        "df.bfill(inplace=True) #Backward fill\n",
        "print(df.isnull().any())  #If any null values, returns True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KgdtJSe8rPq",
        "outputId": "9dc2f760-b2af-4ffd-aa53-93f1e2092d03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId    False\n",
            "Survived       False\n",
            "Pclass         False\n",
            "Name           False\n",
            "Sex            False\n",
            "Age            False\n",
            "SibSp          False\n",
            "Parch          False\n",
            "Ticket         False\n",
            "Fare           False\n",
            "Cabin          False\n",
            "Embarked       False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling different columns\n",
        "#Drop ones that don't contribute\n",
        "df.drop('PassengerId',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "WluW_u4NVBmO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode nominal categorical values\n",
        "df[\"Sex\"]=df[\"Sex\"].map({\"male\":0,\"female\":1})"
      ],
      "metadata": {
        "id": "O1OraC8YopLG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract useful prefixes\n",
        "import re\n",
        "df[\"Title\"]=df[\"Name\"].str.extract(r\",\\s*([^\\.]+)\\.\")\n",
        "df.drop(\"Name\",axis=1,inplace=True)\n",
        "df[\"Deck\"] = df[\"Ticket\"].str.extract(r\"([A-Za-z\\.]+)\")\n",
        "df[\"Deck\"] = df[\"Deck\"].fillna(\"NoPrefix\")\n",
        "df.drop(\"Ticket\", axis=1, inplace=True)\n",
        "#But too many prefixes for deck\n",
        "threshold=10\n",
        "prefix_counts = df[\"Deck\"].value_counts()\n",
        "rare_prefixes = prefix_counts[prefix_counts < threshold].index\n",
        "df[\"Deck\"] = df[\"Deck\"].replace(rare_prefixes, 'Other')\n",
        "# One-Hot Encode 'Deck' column, drop_first=True avoids dummy variable trap\n",
        "df = pd.get_dummies(df, columns=[\"Deck\"], drop_first=True)"
      ],
      "metadata": {
        "id": "eRnGWSRXosMn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After data preprocessing\n",
        "print(df.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE8haYKUweo0",
        "outputId": "9bb651f8-0521-4e4f-ce30-03923ac74767"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare Cabin Embarked Title  \\\n",
            "0         0       3    0  22.0      1      0   7.2500   C85        S    Mr   \n",
            "1         1       1    1  38.0      1      0  71.2833   C85        C   Mrs   \n",
            "\n",
            "   Deck_C.A.  Deck_NoPrefix  Deck_Other  Deck_PC  Deck_SC  Deck_SOTON  \\\n",
            "0      False          False       False    False    False       False   \n",
            "1      False          False       False     True    False       False   \n",
            "\n",
            "   Deck_STON  \n",
            "0      False  \n",
            "1      False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train and Test Data Splitting"
      ],
      "metadata": {
        "id": "0m3ihRxxonfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X=df.drop(\"Survived\",axis=1)\n",
        "y=df[\"Survived\"]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42,stratify=y)"
      ],
      "metadata": {
        "id": "LX1OCWg3qnkn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic Filter methods\n",
        "cat_columns = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "X_train=pd.get_dummies(X_train,columns=cat_columns,drop_first=True)\n",
        "X_train=X_train.astype(int)\n",
        "X_test=pd.get_dummies(X_test,columns=cat_columns,drop_first=True)\n",
        "X_test=X_test.astype(int)\n",
        "#Removing Constant features\n",
        "const = []\n",
        "for features in X_train:\n",
        "  if(X_train[features].std()==0):\n",
        "    const.append(features)\n",
        "print(\"Number of constant features:\",len(const))\n",
        "X_train.drop(labels=const,axis=1,inplace=True)\n",
        "X_test.drop(labels=const,axis=1,inplace=True)\n",
        "\n",
        "#Removing quasi constant features\n",
        "quasi_constant = []\n",
        "for feature in X_train.columns:\n",
        "  predominant = (X_train[feature].value_counts()/float(len(X_train))).sort_values(ascending=False).values[0]\n",
        "  if(predominant>0.999):\n",
        "    quasi_constant.append(feature)\n",
        "print(\"Number of quasi constant features:\",len(quasi_constant))\n",
        "X_train.drop(labels=quasi_constant,axis=1,inplace=True)\n",
        "X_test.drop(labels=quasi_constant,axis=1,inplace=True)#Apply same removal to X_test\n",
        "\n",
        "#Duplicated features\n",
        "duplicates = []\n",
        "for i in range(len(X_train.columns)):\n",
        "  col1 = X_train.columns[i]\n",
        "  for col2 in X_train.columns[i+1:]:\n",
        "    if(X_train[col1].equals(X_train[col2])): #Not ==, as it won't return a single True of False\n",
        "      duplicates.append(col2)\n",
        "print(\"Number of duplicate features:\",len(duplicates))\n",
        "X_train.drop(labels=duplicates,axis=1,inplace=True)\n",
        "X_test.drop(labels=duplicates,axis=1,inplace=True)#Apply same removal to X_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U-F44Q2myJp",
        "outputId": "6eaac80f-e259-4af9-e1b0-60ada1273db3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of constant features: 0\n",
            "Number of quasi constant features: 0\n",
            "Number of duplicate features: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Statistical Filter Methods\n",
        "num_features=[col for col in X_train.columns if not set(X_train[col].unique()).issubset({0,1})]\n",
        "cat_features = [col for col in X_train.columns if set(X_train[col].unique()).issubset({0,1})]\n",
        "from sklearn.feature_selection import f_classif,SelectKBest\n",
        "#1. Anova\n",
        "f_values,p_values = f_classif(X_train[num_features],y_train)\n",
        "anova_df=pd.DataFrame({\n",
        "    \"Numerical Features\":num_features,\n",
        "    \"F_values\":f_values,\n",
        "    \"P_values\":p_values\n",
        "    })\n",
        "anova_df.sort_values(by=\"P_values\",inplace=True)\n",
        "significant_numeric_features = anova_df[anova_df[\"P_values\"]<0.05][\"Numerical Features\"].tolist()\n",
        "print(\"Selected Numerical Features:\", significant_numeric_features)\n",
        "#2.chi2\n",
        "from sklearn.feature_selection import chi2\n",
        "chi2_values,p_values=chi2(X_train[cat_features],y_train)\n",
        "chi2_df=pd.DataFrame({\n",
        "    \"Categorical Features\":cat_features,\n",
        "    \"Chi2_values\":chi2_values,\n",
        "    \"p_values\":p_values\n",
        "     })\n",
        "chi2_df.sort_values(by=\"p_values\",inplace=True)\n",
        "significant_chi2_features=chi2_df[chi2_df[\"p_values\"]<0.05][\"Categorical Features\"].tolist()\n",
        "print(\"Selected Features from Chi2 test:\", significant_chi2_features)\n",
        "#3. Mutual info\n",
        "from sklearn.feature_selection import mutual_info_classif,SelectKBest\n",
        "selector = SelectKBest(score_func=mutual_info_classif,k=10)\n",
        "selector.fit(X_train[cat_features],y_train)\n",
        "significant_mi_features=X_train[cat_features].columns[selector.get_support()].tolist()\n",
        "print(\"Selected Features from MI test:\",significant_mi_features)\n",
        "final_selected_features=list(set(significant_numeric_features+significant_chi2_features+significant_mi_features)) #Set conversion is for removing duplicates, converting to list is to use it as indexer\n",
        "#Filter\n",
        "X_train=X_train[final_selected_features]\n",
        "for col in X_train.columns:\n",
        "    if col not in X_test.columns:\n",
        "        X_test[col] = 0\n",
        "X_test = X_test[X_train.columns]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9F8cpf-6Xsd",
        "outputId": "4adf975e-8747-4587-f8d3-c6104b6bf216"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Numerical Features: ['Pclass', 'Fare', 'Parch', 'Age']\n",
            "Selected Features from Chi2 test: ['Sex', 'Title_Mr', 'Title_Mrs', 'Title_Miss', 'Deck_PC', 'Embarked_S', 'Cabin_A34', 'Cabin_D33', 'Cabin_C110', 'Title_Master']\n",
            "Selected Features from MI test: ['Sex', 'Deck_NoPrefix', 'Cabin_B73', 'Cabin_C124', 'Cabin_C99', 'Cabin_D56', 'Title_Don', 'Title_Miss', 'Title_Mr', 'Title_Mrs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset after data preprocessing and feature selection\n",
        "print(X_train.columns)\n",
        "print(X_train.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Zw31xGNfMf",
        "outputId": "10bf6219-7f89-4304-8f79-461296f1e6a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Title_Mr', 'Cabin_D33', 'Deck_NoPrefix', 'Pclass', 'Fare', 'Title_Mrs',\n",
            "       'Cabin_B73', 'Cabin_C99', 'Title_Don', 'Age', 'Parch', 'Cabin_A34',\n",
            "       'Cabin_C110', 'Deck_PC', 'Cabin_C124', 'Embarked_S', 'Title_Miss',\n",
            "       'Sex', 'Title_Master', 'Cabin_D56'],\n",
            "      dtype='object')\n",
            "     Title_Mr  Cabin_D33  Deck_NoPrefix  Pclass  Fare  Title_Mrs  Cabin_B73  \\\n",
            "748         1          0              1       1    53          0          0   \n",
            "45          1          0              0       3     8          0          0   \n",
            "28          0          0              1       3     7          0          0   \n",
            "\n",
            "     Cabin_C99  Title_Don  Age  Parch  Cabin_A34  Cabin_C110  Deck_PC  \\\n",
            "748          0          0   19      0          0           0        0   \n",
            "45           0          0   19      0          0           0        0   \n",
            "28           0          0   19      0          0           0        0   \n",
            "\n",
            "     Cabin_C124  Embarked_S  Title_Miss  Sex  Title_Master  Cabin_D56  \n",
            "748           0           1           0    0             0          0  \n",
            "45            0           1           0    0             0          0  \n",
            "28            0           0           1    1             0          0  \n"
          ]
        }
      ]
    }
  ]
}